# ğŸ“ˆ Telco Customer Churn Prediction

**Dá»± bÃ¡o KhÃ¡ch hÃ ng Rá»i bá» Dá»‹ch vá»¥ Viá»…n thÃ´ng**

## ğŸ§  Giá»›i thiá»‡u Dá»± Ã¡n

ÄÃ¢y lÃ  **dá»± Ã¡n cuá»‘i ká»³ mÃ´n Machine Learning**, táº­p trung vÃ o viá»‡c phÃ¢n tÃ­ch dá»¯ liá»‡u khÃ¡ch hÃ ng trong lÄ©nh vá»±c viá»…n thÃ´ng vÃ  xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y nháº±m **dá»± Ä‘oÃ¡n kháº£ nÄƒng khÃ¡ch hÃ ng rá»i bá» dá»‹ch vá»¥ (Customer Churn)**.

BÃ i toÃ¡n churn prediction cÃ³ Ã½ nghÄ©a thá»±c tiá»…n cao, giÃºp doanh nghiá»‡p:

* Nháº­n diá»‡n sá»›m nhÃ³m khÃ¡ch hÃ ng cÃ³ nguy cÆ¡ rá»i bá»
* Chá»§ Ä‘á»™ng triá»ƒn khai cÃ¡c chiáº¿n lÆ°á»£c giá»¯ chÃ¢n khÃ¡ch hÃ ng
* Tá»‘i Æ°u chi phÃ­ marketing vÃ  nÃ¢ng cao giÃ¡ trá»‹ vÃ²ng Ä‘á»i khÃ¡ch hÃ ng (Customer Lifetime Value)

## ğŸ¯ Má»¥c tiÃªu Dá»± Ã¡n

* PhÃ¢n tÃ­ch hÃ nh vi vÃ  Ä‘áº·c Ä‘iá»ƒm cá»§a khÃ¡ch hÃ ng viá»…n thÃ´ng
* Thá»±c hiá»‡n **EDA (Exploratory Data Analysis)** Ä‘á»ƒ hiá»ƒu dá»¯ liá»‡u
* Tiá»n xá»­ lÃ½ vÃ  chuáº©n hÃ³a dá»¯ liá»‡u theo quy trÃ¬nh Machine Learning chuáº©n
* XÃ¢y dá»±ng vÃ  so sÃ¡nh nhiá»u mÃ´ hÃ¬nh dá»± bÃ¡o Churn
* Lá»±a chá»n mÃ´ hÃ¬nh tá»‘i Æ°u vÃ  triá»ƒn khai dá»± bÃ¡o cho khÃ¡ch hÃ ng má»›i

## ğŸ“‚ Cáº¥u trÃºc ThÆ° má»¥c Dá»± Ã¡n

```
Project_Cuoi_Ki/
â”‚
â”œâ”€â”€ data/  
â”‚   â””â”€â”€ Chá»©a dá»¯ liá»‡u gá»‘c (Raw Data)
â”‚
â”œâ”€â”€ folder_clean_visual/  
â”‚   â””â”€â”€ Dá»¯ liá»‡u Ä‘Ã£ lÃ m sáº¡ch sau EDA vÃ  cÃ¡c biá»ƒu Ä‘á»“ trá»±c quan
â”‚
â”œâ”€â”€ folder_standardized/  
â”‚   â””â”€â”€ Dá»¯ liá»‡u Ä‘Ã£ chuáº©n hÃ³a (Train/Test)
â”‚   â””â”€â”€ LÆ°u Scaler vÃ  Encoder phá»¥c vá»¥ dá»± Ä‘oÃ¡n
â”‚
â”œâ”€â”€ models_and_results/  
â”‚   â””â”€â”€ CÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n (.pkl)
â”‚   â””â”€â”€ Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh
â”‚
â”œâ”€â”€ EDA.ipynb  
â”‚   â””â”€â”€ KhÃ¡m phÃ¡ dá»¯ liá»‡u, xá»­ lÃ½ missing values, trá»±c quan hÃ³a
â”‚
â”œâ”€â”€ processing.ipynb  
â”‚   â””â”€â”€ Feature Engineering, Encoding, Train/Test Split, Standardization
â”‚
â”œâ”€â”€ logisticRegression.ipynb  
â”‚   â””â”€â”€ Huáº¥n luyá»‡n mÃ´ hÃ¬nh Logistic Regression
â”‚
â”œâ”€â”€ randomForest.ipynb  
â”‚   â””â”€â”€ Huáº¥n luyá»‡n mÃ´ hÃ¬nh Random Forest
â”‚
â”œâ”€â”€ XGBoosting.ipynb  
â”‚   â””â”€â”€ Huáº¥n luyá»‡n vÃ  tá»‘i Æ°u mÃ´ hÃ¬nh XGBoost
â”‚
â”œâ”€â”€ model_comparison.ipynb  
â”‚   â””â”€â”€ So sÃ¡nh hiá»‡u nÄƒng cÃ¡c mÃ´ hÃ¬nh
â”‚
â”œâ”€â”€ predict.ipynb  
â”‚   â””â”€â”€ Dá»± bÃ¡o churn cho khÃ¡ch hÃ ng má»›i
â”‚
â””â”€â”€ requirements.txt  
    â””â”€â”€ Danh sÃ¡ch thÆ° viá»‡n cáº§n thiáº¿t
```

## âš™ï¸ HÆ°á»›ng dáº«n CÃ i Ä‘áº·t & Cháº¡y Dá»± Ã¡n

### 1ï¸âƒ£ CÃ i Ä‘áº·t mÃ´i trÆ°á»ng

Khuyáº¿n nghá»‹ sá»­ dá»¥ng **Anaconda** hoáº·c **Virtual Environment** Ä‘á»ƒ Ä‘áº£m báº£o tÃ­nh á»•n Ä‘á»‹nh.

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Quy trÃ¬nh Thá»±c hiá»‡n

Äá»ƒ Ä‘áº£m báº£o **tÃ­nh nháº¥t quÃ¡n vÃ  tÃ¡i láº­p káº¿t quáº£**, cÃ¡c notebook cáº§n Ä‘Æ°á»£c cháº¡y theo Ä‘Ãºng thá»© tá»±:

1. **EDA.ipynb**

   * Äá»c dá»¯ liá»‡u gá»‘c
   * Xá»­ lÃ½ missing values
   * PhÃ¢n tÃ­ch phÃ¢n phá»‘i vÃ  má»‘i quan há»‡ giá»¯a cÃ¡c biáº¿n

2. **processing.ipynb**

   * Feature Engineering
   * One-Hot Encoding
   * Chia Train/Test
   * Chuáº©n hÃ³a dá»¯ liá»‡u

3. **Huáº¥n luyá»‡n mÃ´ hÃ¬nh**

   * `logisticRegression.ipynb`
   * `randomForest.ipynb`
   * `XGBoosting.ipynb`

   ğŸ‘‰ Ãp dá»¥ng **SMOTE** Ä‘á»ƒ xá»­ lÃ½ máº¥t cÃ¢n báº±ng dá»¯ liá»‡u (Imbalanced Dataset)

4. **model_comparison.ipynb**

   * Tá»•ng há»£p vÃ  so sÃ¡nh cÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡
   * Lá»±a chá»n mÃ´ hÃ¬nh tá»‘t nháº¥t

5. **predict.ipynb**

   * Sá»­ dá»¥ng mÃ´ hÃ¬nh tá»‘i Æ°u Ä‘á»ƒ dá»± bÃ¡o churn cho khÃ¡ch hÃ ng má»›i

## ğŸ§ª CÃ¡c Thuáº­t toÃ¡n ÄÆ°á»£c Sá»­ dá»¥ng

* Logistic Regression
* Random Forest Classifier
* XGBoost Classifier

## ğŸ› ï¸ Ká»¹ thuáº­t & PhÆ°Æ¡ng phÃ¡p Ná»•i báº­t

* **SMOTE Pipeline** xá»­ lÃ½ máº¥t cÃ¢n báº±ng dá»¯ liá»‡u
* **RandomizedSearchCV** tá»‘i Æ°u siÃªu tham sá»‘
* **Threshold Tuning** Ä‘á»ƒ cáº£i thiá»‡n F1-Score
* ÄÃ¡nh giÃ¡ báº±ng cÃ¡c metric: Precision, Recall, F1-Score

## ğŸ“Š Káº¿t quáº£ Ná»•i báº­t

* **MÃ´ hÃ¬nh tá»‘t nháº¥t:** XGBoost Classifier
* **NgÆ°á»¡ng phÃ¢n loáº¡i tá»‘i Æ°u (Best Threshold):** ~0.54
* **Hiá»‡u nÄƒng:**

  * F1-Score cao
  * CÃ¢n báº±ng tá»‘t giá»¯a Precision vÃ  Recall
* MÃ´ hÃ¬nh phÃ¹ há»£p cho cÃ¡c bÃ i toÃ¡n churn prediction trong thá»±c táº¿

## ğŸ“Œ Káº¿t luáº­n

Dá»± Ã¡n Ä‘Ã£ xÃ¢y dá»±ng thÃ nh cÃ´ng má»™t **pipeline Machine Learning hoÃ n chá»‰nh**, tá»« phÃ¢n tÃ­ch dá»¯ liá»‡u, tiá»n xá»­ lÃ½, huáº¥n luyá»‡n mÃ´ hÃ¬nh Ä‘áº¿n triá»ƒn khai dá»± bÃ¡o. Káº¿t quáº£ cho tháº¥y **XGBoost káº¿t há»£p SMOTE vÃ  Threshold Tuning** lÃ  lá»±a chá»n hiá»‡u quáº£ cho bÃ i toÃ¡n dá»± bÃ¡o khÃ¡ch hÃ ng rá»i bá» dá»‹ch vá»¥ viá»…n thÃ´ng.
