{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc994307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ba68fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- KHỞI TẠO PROCESSING ---\n"
     ]
    }
   ],
   "source": [
    "# Cấu hình đường dẫn đầu vào/đầu ra\n",
    "input_path = 'folder_clean_visual/telco_clean.csv'\n",
    "output_folder = 'folder_standardized'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "df = None\n",
    "\n",
    "print(\"--- KHỞI TẠO PROCESSING ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4858100d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. LOAD CLEAN DATA\n",
      "   - Đã đọc dữ liệu: (7021, 20)\n"
     ]
    }
   ],
   "source": [
    "def load_clean_data():\n",
    "    \"\"\"\n",
    "    Đọc dữ liệu đã làm sạch từ bước EDA.\n",
    "    \n",
    "    Raises:\n",
    "        FileNotFoundError: Nếu không tìm thấy file dữ liệu sạch\n",
    "    \"\"\"\n",
    "    global df\n",
    "    print(\"\\n1. LOAD CLEAN DATA\")\n",
    "    if os.path.exists(input_path):\n",
    "        df = pd.read_csv(input_path)\n",
    "        print(f\"   - Đã đọc dữ liệu: {df.shape}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"   ✗ Không tìm thấy file {input_path}. Hãy chạy EDA.ipynb trước!\")\n",
    "\n",
    "load_clean_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db110366",
   "metadata": {},
   "source": [
    "# FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8242fa1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. FEATURE ENGINEERING\n",
      "   - Thêm các cột: Has_Family, Num_Services, Payment_Type, Avg_Charges_Per_Service\n",
      "   - Kích thước dữ liệu: (7021, 24)\n"
     ]
    }
   ],
   "source": [
    "def create_new_features():\n",
    "    \"\"\"\n",
    "    Tạo các đặc trưng mới (Feature Engineering) để cải thiện khả năng dự báo.\n",
    "    Bao gồm: Has_Family, Num_Services, Payment_Type, Avg_Charges_Per_Service\n",
    "    \"\"\"\n",
    "    global df\n",
    "    print(\"\\n2. FEATURE ENGINEERING\")\n",
    "    \n",
    "    # Has_Family: Khách hàng có gia đình (Partner hoặc Dependents)\n",
    "    df['Has_Family'] = ((df['Partner'] == 'Yes') | (df['Dependents'] == 'Yes')).astype(int)\n",
    "    \n",
    "    # Num_Services: Tổng số dịch vụ gia tăng mà khách hàng sử dụng\n",
    "    services = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', \n",
    "                'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
    "    df['Num_Services'] = (df[services] == 'Yes').sum(axis=1)\n",
    "    \n",
    "    # Payment_Type: Phân loại hình thức thanh toán (Automatic vs Manual)\n",
    "    df['Payment_Type'] = df['PaymentMethod'].apply(\n",
    "        lambda x: 'Automatic' if 'automatic' in x.lower() else 'Manual'\n",
    "    )\n",
    "    \n",
    "    # Avg_Charges_Per_Service: Cước phí trung bình trên mỗi dịch vụ (+1 tránh chia cho 0)\n",
    "    df['Avg_Charges_Per_Service'] = df['MonthlyCharges'] / (df['Num_Services'] + 1)\n",
    "\n",
    "    print(\"   - Thêm các cột: Has_Family, Num_Services, Payment_Type, Avg_Charges_Per_Service\")\n",
    "    print(f\"   - Kích thước dữ liệu: {df.shape}\")\n",
    "\n",
    "create_new_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18a2012",
   "metadata": {},
   "source": [
    "# ENCODING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87fded56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. ENCODING DATA\n",
      "   - Encode 'Churn': Yes=1, No=0\n",
      "   ℹ Tìm thấy 16 cột cần One-Hot Encoding\n",
      "   - Shape sau One-Hot Encoding: (7021, 35)\n"
     ]
    }
   ],
   "source": [
    "def encode_data():\n",
    "    \"\"\"\n",
    "    Thực hiện Label Encoding cho biến mục tiêu (Churn) \n",
    "    và One-Hot Encoding cho các biến phân loại còn lại.\n",
    "    \"\"\"\n",
    "    global df\n",
    "    print(\"\\n3. ENCODING DATA\")\n",
    "    \n",
    "    # Label Encoding cho biến mục tiêu Churn (Yes=1, No=0)\n",
    "    le = LabelEncoder()\n",
    "    df['Churn'] = le.fit_transform(df['Churn'])\n",
    "    joblib.dump(le, os.path.join(output_folder, 'label_encoder_churn.pkl'))\n",
    "    print(f\"   - Encode 'Churn': Yes=1, No=0\")\n",
    "\n",
    "    # One-Hot Encoding cho các biến phân loại còn lại\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    print(f\"   ℹ Tìm thấy {len(categorical_cols)} cột cần One-Hot Encoding\")\n",
    "    \n",
    "    df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "    print(f\"   - Shape sau One-Hot Encoding: {df.shape}\")\n",
    "\n",
    "encode_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c756d5e",
   "metadata": {},
   "source": [
    "# TRAIN/TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bc11d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. TRAIN/TEST SPLIT\n",
      "   - Kích thước tập Train: (5616, 34)\n",
      "   - Kích thước tập Test: (1405, 34)\n",
      "    Tỷ lệ: 80.0% Train, 20% Test\n"
     ]
    }
   ],
   "source": [
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "\n",
    "def split_data():\n",
    "    \"\"\"\n",
    "    Chia dữ liệu thành tập Train (80%) và Test (20%) trước khi chuẩn hóa.\n",
    "    Điều này đảm bảo không xảy ra data leakage từ tập Test vào quá trình Training.\n",
    "    \"\"\"\n",
    "    global df, X_train, X_test, y_train, y_test\n",
    "    print(\"\\n4. TRAIN/TEST SPLIT\")\n",
    "    \n",
    "    # Tách biến mục tiêu (y) và các đặc trưng (X)\n",
    "    X = df.drop('Churn', axis=1)\n",
    "    y = df['Churn']\n",
    "    \n",
    "    # Chia tập với random_state=42 để đảm bảo tái tạo được kết quả\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"   - Kích thước tập Train: {X_train.shape}\")\n",
    "    print(f\"   - Kích thước tập Test: {X_test.shape}\")\n",
    "    print(f\"    Tỷ lệ: {X_train.shape[0] / (X_train.shape[0] + X_test.shape[0]) * 100:.1f}% Train, 20% Test\")\n",
    "\n",
    "split_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e3b33b",
   "metadata": {},
   "source": [
    "# SCALE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "360903e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. SCALE DATA\n",
      "   - Chuyển 5 cột sang kiểu float\n",
      "   - Chuẩn hóa MinMax thành công (phạm vi [0, 1])\n",
      "   - Lưu Scaler tại: folder_standardized\\minmax_scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "def scale_data_correctly():\n",
    "    \"\"\"\n",
    "    Chuẩn hóa dữ liệu số bằng MinMax Scaling (giới hạn [0, 1]).\n",
    "    \n",
    "    ⚠ Quy tắc quan trọng: Fit trên X_train, Transform trên X_train và X_test\n",
    "    để tránh data leakage (thông tin từ Test set lọt vào Training).\n",
    "    \"\"\"\n",
    "    global X_train, X_test\n",
    "    print(\"\\n5. SCALE DATA\")\n",
    "    \n",
    "    # Danh sách các cột số cần chuẩn hóa\n",
    "    cols_to_scale = ['tenure', 'MonthlyCharges', 'TotalCharges', \n",
    "                     'Num_Services', 'Avg_Charges_Per_Service']\n",
    "    \n",
    "    # Chuyển đổi sang float trước khi scale\n",
    "    X_train[cols_to_scale] = X_train[cols_to_scale].astype(float)\n",
    "    X_test[cols_to_scale] = X_test[cols_to_scale].astype(float)\n",
    "    print(f\"   - Chuyển {len(cols_to_scale)} cột sang kiểu float\")\n",
    "\n",
    "    # Khởi tạo MinMax Scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # Fit và Transform trên tập Train\n",
    "    X_train.loc[:, cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n",
    "    \n",
    "    # Chỉ Transform (không Fit) trên tập Test\n",
    "    X_test.loc[:, cols_to_scale] = scaler.transform(X_test[cols_to_scale])\n",
    "    \n",
    "    # Lưu scaler để dùng cho dữ liệu mới sau này\n",
    "    scaler_path = os.path.join(output_folder, 'minmax_scaler.pkl')\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    \n",
    "    print(f\"   - Chuẩn hóa MinMax thành công (phạm vi [0, 1])\")\n",
    "    print(f\"   - Lưu Scaler tại: {scaler_path}\")\n",
    "\n",
    "scale_data_correctly()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7471d0",
   "metadata": {},
   "source": [
    "# SAVE PROCESSED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "273ebbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. SAVE PROCESSED DATA\n",
      "   - Lưu X_train, X_test, y_train, y_test\n",
      "   - Lưu danh sách cột (train_columns.pkl)\n",
      "\n",
      "   → Tất cả files đã lưu tại thư mục: folder_standardized\n"
     ]
    }
   ],
   "source": [
    "def save_processed_files():\n",
    "    \"\"\"\n",
    "    Lưu các tập dữ liệu đã xử lý và các công cụ cần thiết cho bước Training/Prediction.\n",
    "    \n",
    "    Files lưu:\n",
    "    - X_train.csv, X_test.csv: Dữ liệu đặc trưng\n",
    "    - y_train.csv, y_test.csv: Biến mục tiêu\n",
    "    - train_columns.pkl: Danh sách cột để đảm bảo khớp khi dự báo trên dữ liệu mới\n",
    "    \"\"\"\n",
    "    global X_train, X_test, y_train, y_test\n",
    "    print(\"\\n6. SAVE PROCESSED DATA\")\n",
    "    \n",
    "    # Lưu các tập dữ liệu\n",
    "    X_train.to_csv(os.path.join(output_folder, 'X_train.csv'), index=False)\n",
    "    X_test.to_csv(os.path.join(output_folder, 'X_test.csv'), index=False)\n",
    "    y_train.to_csv(os.path.join(output_folder, 'y_train.csv'), index=False)\n",
    "    y_test.to_csv(os.path.join(output_folder, 'y_test.csv'), index=False)\n",
    "    print(f\"   - Lưu X_train, X_test, y_train, y_test\")\n",
    "    \n",
    "    # Lưu danh sách tên cột để dùng cho dữ liệu mới (đảm bảo khớp cột)\n",
    "    joblib.dump(X_train.columns.tolist(), \n",
    "                os.path.join(output_folder, 'train_columns.pkl'))\n",
    "    print(f\"   - Lưu danh sách cột (train_columns.pkl)\")\n",
    "    \n",
    "    print(f\"\\n   → Tất cả files đã lưu tại thư mục: {output_folder}\")\n",
    "\n",
    "save_processed_files()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
